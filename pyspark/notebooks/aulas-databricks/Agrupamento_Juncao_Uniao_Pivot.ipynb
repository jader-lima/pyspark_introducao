{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd47d334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, FloatType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3ec350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/13 14:58:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/13 14:58:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName(\"Iniciando com Spark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ddf012",
   "metadata": {},
   "source": [
    "### Lendo Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21413525",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_countries = '/mnt/datalake/transient/departments/countries'\n",
    "df_countries = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_countries)\n",
    "#transient\\csv\\olist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "827562bc-12da-4d86-8ca6-e569c57b8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_regions = '/mnt/datalake/transient/departments/regions'\n",
    "df_regions = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "40b044f3-8421-4648-bcda-f216f1330d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_jobs = '/mnt/datalake/transient/departments/jobs'\n",
    "df_jobs = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "524de348-6108-434a-a838-537e86389e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_employees = '/mnt/datalake/transient/departments/employees'\n",
    "df_employees = spark.read.format('csv')\\\n",
    ".option(\"header\", True)\\\n",
    ".option(\"sep\", \",\")\\\n",
    ".option(\"quote\",\"\\'\")\\\n",
    ".option(\"inferSchema\",True)\\\n",
    ".load(path_employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a400f9-59f1-4f3f-8371-f2a69adb8ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23defc96-1e02-45d7-8c83-ef7cf57a0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+\n",
      "|country_id|country_name|region_id|\n",
      "+----------+------------+---------+\n",
      "|        AR|   Argentina|        2|\n",
      "|        AU|   Australia|        3|\n",
      "+----------+------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_countries.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b3f088-8829-41ef-8dd7-c0f8b4b41ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|region_id|         region_name|\n",
      "+---------+--------------------+\n",
      "|        1|              Europe|\n",
      "|        2|            Americas|\n",
      "|        3|                Asia|\n",
      "|        4|Middle East and A...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b47294ea-9e68-4680-af60-0f8a3f63988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(97,\"Terra Média\"),(98,\"Westeros\"),(98,\"Esteros\"),(100,\"Sistema Solar\")]\n",
    "\n",
    "\n",
    "schema = StructType([ \\\n",
    "    StructField(\"region_id\",IntegerType(),True), \\\n",
    "    StructField(\"region_name\",StringType(),True)\n",
    "  ])\n",
    "\n",
    "df_region2 = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19768d00-ee4a-4a86-8984-83e8d5cf879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(50,\"Valfenda\",91),(51,\"Kings Landing\",98),(51,\"Terra\",101)]\n",
    "\n",
    "#country_id|country_name|region_id\n",
    "schema = StructType([ \\\n",
    "    StructField(\"country_id\",IntegerType(),True), \\\n",
    "    StructField(\"country_name\",StringType(),True), \\\n",
    "    StructField(\"region_id\",IntegerType(),True),\n",
    "  ])\n",
    "\n",
    "df_countries2 = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf45a34-aee6-4628-8a72-1e2a520a9d4d",
   "metadata": {},
   "source": [
    "### **Union** ###\n",
    "Podemos unir dataframes que tenham o mesmo schema, o efeito seria o mesmo de empilhar os dataframes <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e8f4a9-51de-4e2a-aad3-33fc7de8ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions3 = df_regions.union(df_region2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed901e71-763f-4978-92a4-0124c0499e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|region_id|         region_name|\n",
      "+---------+--------------------+\n",
      "|        1|              Europe|\n",
      "|        2|            Americas|\n",
      "|        3|                Asia|\n",
      "|        4|Middle East and A...|\n",
      "|       97|         Terra Média|\n",
      "|       98|            Westeros|\n",
      "|       99|             Esteros|\n",
      "|      100|          Via Lactea|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_regions3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a23c50f-5b8d-4bbd-9dc0-cb1a68efbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_countries3 = df_countries.union(df_countries2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3710e057-3087-4bf5-bf62-0987e16dbeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---------+\n",
      "|country_id|        country_name|region_id|\n",
      "+----------+--------------------+---------+\n",
      "|        AR|           Argentina|        2|\n",
      "|        AU|           Australia|        3|\n",
      "|        BE|             Belgium|        1|\n",
      "|        BR|              Brazil|        2|\n",
      "|        CA|              Canada|        2|\n",
      "|        CH|         Switzerland|        1|\n",
      "|        CN|               China|        3|\n",
      "|        DE|             Germany|        1|\n",
      "|        DK|             Denmark|        1|\n",
      "|        EG|               Egypt|        4|\n",
      "|        FR|              France|        1|\n",
      "|        HK|            HongKong|        3|\n",
      "|        IL|              Israel|        4|\n",
      "|        IN|               India|        3|\n",
      "|        IT|               Italy|        1|\n",
      "|        JP|               Japan|        3|\n",
      "|        KW|              Kuwait|        4|\n",
      "|        MX|              Mexico|        2|\n",
      "|        NG|             Nigeria|        4|\n",
      "|        NL|         Netherlands|        1|\n",
      "|        SG|           Singapore|        3|\n",
      "|        UK|      United Kingdom|        1|\n",
      "|        US|United States of ...|        2|\n",
      "|        ZM|              Zambia|        4|\n",
      "|        ZW|            Zimbabwe|        4|\n",
      "|        50|            Valfenda|       91|\n",
      "|        51|       Kings Landing|       98|\n",
      "|        51|               Terra|      101|\n",
      "+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_countries3.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615a07a-2d21-4ae2-afac-084a2d008220",
   "metadata": {},
   "source": [
    "### **Join** ###\n",
    "Outra possibilidade muito utilizada é a **junção** ou **join** entre dataframes, a junção necessita que os dataframes envolvidos tenham um campo em comum, semelhante a relação de chaves primarias e estrageiras do SQL tradicional<br>\n",
    "**Tipos de junções**;<br>\n",
    "• inner - Junção padrão, só realiza a junção se a mesma chave exista em todos os dataframes envolvidos ;<br>\n",
    "• left - Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da esquerda não sejam encontrados, as colunas desse dataframe ;<br>\n",
    "• full - ;<br>\n",
    "• anti - ;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d731f-2bd6-4316-83ae-dc7955652710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06facfb8-4677-42b5-ab5a-bdace7124c6b",
   "metadata": {},
   "source": [
    "### **Inner Join** ###\n",
    "Outra possibilidade muito utilizada é a **junção** ou **join** entre dataframes, a junção necessita que os dataframes envolvidos tenham um campo em comum, semelhante a relação de chaves primarias e estrageiras do SQL tradicional<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cc0276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83e2c769-5601-4634-b6e4-05b9abd75626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|       98|            Westeros|        51|       Kings Landing|       98|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743d34d-15c2-4b28-aaa1-b5dd114a274f",
   "metadata": {},
   "source": [
    "### **Left Join** ###\n",
    "Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da direita não sejam encontrados, as colunas desse dataframe aparecem como nulas;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41f07553-d9b8-42b8-980e-95673f8c96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "899d1bfa-b20d-4dab-bd5e-de5132b92c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|       97|         Terra Média|      null|                null|     null|\n",
      "|       98|            Westeros|      null|                null|     null|\n",
      "|       99|             Esteros|      null|                null|     null|\n",
      "|      100|          Via Lactea|      null|                null|     null|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e024d-9c85-4176-be04-ed9abeb4f920",
   "metadata": {},
   "source": [
    "### **Full Join** ###\n",
    "Sempre retorna os elementos do dataframe da esquerda, os caso os elementos do dataframe da direita não sejam encontrados, as colunas desse dataframe aparecem como nulas;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50612352-3bd2-4d50-a128-d13a86489acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries3.region_id\n",
    "df_join = df_regions3.join(df_countries3, condicao ,'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "247c4a0c-8db2-4333-b52f-e07eddcd9c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|region_id|         region_name|country_id|        country_name|region_id|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "|        1|              Europe|        BE|             Belgium|        1|\n",
      "|        1|              Europe|        CH|         Switzerland|        1|\n",
      "|        1|              Europe|        DE|             Germany|        1|\n",
      "|        1|              Europe|        DK|             Denmark|        1|\n",
      "|        1|              Europe|        FR|              France|        1|\n",
      "|        1|              Europe|        IT|               Italy|        1|\n",
      "|        1|              Europe|        NL|         Netherlands|        1|\n",
      "|        1|              Europe|        UK|      United Kingdom|        1|\n",
      "|        2|            Americas|        AR|           Argentina|        2|\n",
      "|        2|            Americas|        BR|              Brazil|        2|\n",
      "|        2|            Americas|        CA|              Canada|        2|\n",
      "|        2|            Americas|        MX|              Mexico|        2|\n",
      "|        2|            Americas|        US|United States of ...|        2|\n",
      "|        3|                Asia|        AU|           Australia|        3|\n",
      "|        3|                Asia|        CN|               China|        3|\n",
      "|        3|                Asia|        HK|            HongKong|        3|\n",
      "|        3|                Asia|        IN|               India|        3|\n",
      "|        3|                Asia|        JP|               Japan|        3|\n",
      "|        3|                Asia|        SG|           Singapore|        3|\n",
      "|        4|Middle East and A...|        EG|               Egypt|        4|\n",
      "|        4|Middle East and A...|        IL|              Israel|        4|\n",
      "|        4|Middle East and A...|        KW|              Kuwait|        4|\n",
      "|        4|Middle East and A...|        NG|             Nigeria|        4|\n",
      "|        4|Middle East and A...|        ZM|              Zambia|        4|\n",
      "|        4|Middle East and A...|        ZW|            Zimbabwe|        4|\n",
      "|     null|                null|        50|            Valfenda|       91|\n",
      "|       97|         Terra Média|      null|                null|     null|\n",
      "|       98|            Westeros|        51|       Kings Landing|       98|\n",
      "|       99|             Esteros|      null|                null|     null|\n",
      "|      100|          Via Lactea|      null|                null|     null|\n",
      "+---------+--------------------+----------+--------------------+---------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ce02e8-5e9a-4c2e-9a99-c5d6ee9cec2c",
   "metadata": {},
   "source": [
    "### **Anti Join** ###\n",
    "Sempre retorna os elementos do dataframe da direita, quem não sejam encontrados no dataframe da esquerda;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2697083-799c-4a6f-b742-f6b155686725",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_regions3.region_id == df_countries.region_id\n",
    "df_join = df_regions3.join(df_countries, condicao ,'anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5aacc40e-af4a-4f12-9561-91c334257dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|region_id|region_name|\n",
      "+---------+-----------+\n",
      "|       97|Terra Média|\n",
      "|       98|   Westeros|\n",
      "|       99|    Esteros|\n",
      "|      100| Via Lactea|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8229fbeb-d7d1-489d-b2d5-94cf12421d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c76a0bae-89eb-458d-b85b-018318d337ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1,\"Profit\",100.0),\n",
    "        (2,\"Profit\",100.0),\n",
    "        (3,\"Profit\",100.0),\n",
    "        (4,\"Profit\",100.0),\n",
    "        (5,\"Profit\",100.0),\n",
    "        (6,\"Profit\",100.0),\n",
    "        (7,\"Profit\",100.0),\n",
    "        (8,\"Profit\",100.0),\n",
    "        (9,\"Profit\",100.0),\n",
    "       (10,\"Profit\",100.0),\n",
    "       (11,\"Profit\",100.0),\n",
    "       (12,\"Profit\",100.0),\n",
    "         (1,\"Revenue\",500.0),\n",
    "        (2,\"Revenue\",500.0),\n",
    "        (3,\"Revenue\",500.0),\n",
    "        (4,\"Revenue\",500.0),\n",
    "        (5,\"Revenue\",555.0),\n",
    "        (6,\"Revenue\",777.0),\n",
    "        (7,\"Revenue\",800.0),\n",
    "        (8,\"Revenue\",900.0),\n",
    "        (9,\"Revenue\",1000.0),\n",
    "       (10,\"Revenue\",300.0),\n",
    "       (12,\"Revenue\",400.0)\n",
    "      ]\n",
    "\n",
    "#country_id|country_name|region_id\n",
    "schema = StructType([ \\\n",
    "    StructField(\"Month\",IntegerType(),True), \\\n",
    "    StructField(\"Indicator\",StringType(),True), \\\n",
    "    StructField(\"Amount\",FloatType(),True),\n",
    "  ])\n",
    "\n",
    "df_profit = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9d72952c-c067-4ee1-ac27-25454d8ba25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------+\n",
      "|Month|Indicator|Amount|\n",
      "+-----+---------+------+\n",
      "|    1|   Profit| 100.0|\n",
      "|    2|   Profit| 100.0|\n",
      "|    3|   Profit| 100.0|\n",
      "|    4|   Profit| 100.0|\n",
      "|    5|   Profit| 100.0|\n",
      "|    6|   Profit| 100.0|\n",
      "|    7|   Profit| 100.0|\n",
      "|    8|   Profit| 100.0|\n",
      "|    9|   Profit| 100.0|\n",
      "|   10|   Profit| 100.0|\n",
      "|   11|   Profit| 100.0|\n",
      "|   12|   Profit| 100.0|\n",
      "|    1|  Revenue| 500.0|\n",
      "|    2|  Revenue| 500.0|\n",
      "|    3|  Revenue| 500.0|\n",
      "|    4|  Revenue| 500.0|\n",
      "|    5|  Revenue| 555.0|\n",
      "|    6|  Revenue| 777.0|\n",
      "|    7|  Revenue| 800.0|\n",
      "|    8|  Revenue| 900.0|\n",
      "+-----+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_profit.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e2793271-fda4-446f-ac9e-dc0673121583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Indicator: string (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- 4: double (nullable = true)\n",
      " |-- 5: double (nullable = true)\n",
      " |-- 6: double (nullable = true)\n",
      " |-- 7: double (nullable = true)\n",
      " |-- 8: double (nullable = true)\n",
      " |-- 9: double (nullable = true)\n",
      " |-- 10: double (nullable = true)\n",
      " |-- 11: double (nullable = true)\n",
      " |-- 12: double (nullable = true)\n",
      "\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Indicator|1    |2    |3    |4    |5    |6    |7    |8    |9     |10   |11   |12   |\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Profit   |100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0 |100.0|100.0|100.0|\n",
      "|Revenue  |500.0|500.0|500.0|500.0|555.0|777.0|800.0|900.0|1000.0|300.0|null |400.0|\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pivot = df_profit.groupBy(\"Indicator\").pivot(\"Month\").sum(\"Amount\")\n",
    "df_pivot.printSchema()\n",
    "df_pivot.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "54cf74f5-244f-401b-aa6a-3af1cde366fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Indicator: string (nullable = true)\n",
      " |-- 1: double (nullable = true)\n",
      " |-- 2: double (nullable = true)\n",
      " |-- 3: double (nullable = true)\n",
      " |-- 4: double (nullable = true)\n",
      " |-- 5: double (nullable = true)\n",
      " |-- 6: double (nullable = true)\n",
      " |-- 7: double (nullable = true)\n",
      " |-- 8: double (nullable = true)\n",
      " |-- 9: double (nullable = true)\n",
      " |-- 10: double (nullable = true)\n",
      " |-- 11: double (nullable = true)\n",
      " |-- 12: double (nullable = true)\n",
      "\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Indicator|1    |2    |3    |4    |5    |6    |7    |8    |9     |10   |11   |12   |\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "|Profit   |100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0|100.0 |100.0|100.0|100.0|\n",
      "|Revenue  |500.0|500.0|500.0|500.0|555.0|777.0|800.0|900.0|1000.0|300.0|null |400.0|\n",
      "+---------+-----+-----+-----+-----+-----+-----+-----+-----+------+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "months = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "df_pivot = df_profit.groupBy(\"Indicator\").pivot(\"Month\", months).sum(\"Amount\")\n",
    "df_pivot.printSchema()\n",
    "df_pivot.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781903e8-46dd-4a0b-a2c9-d992f8c12cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UnPivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8d5c631-4cb0-4807-bc8f-8328dccbe201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+------+\n",
      "|Indicator|Month|Amount|\n",
      "+---------+-----+------+\n",
      "|Profit   |1    |100.0 |\n",
      "|Profit   |2    |100.0 |\n",
      "|Profit   |3    |100.0 |\n",
      "|Profit   |4    |100.0 |\n",
      "|Profit   |5    |100.0 |\n",
      "|Profit   |6    |100.0 |\n",
      "|Profit   |7    |100.0 |\n",
      "|Profit   |8    |100.0 |\n",
      "|Profit   |9    |100.0 |\n",
      "|Profit   |10   |100.0 |\n",
      "|Profit   |11   |100.0 |\n",
      "|Profit   |12   |100.0 |\n",
      "|Revenue  |1    |500.0 |\n",
      "|Revenue  |2    |500.0 |\n",
      "|Revenue  |3    |500.0 |\n",
      "|Revenue  |4    |500.0 |\n",
      "|Revenue  |5    |555.0 |\n",
      "|Revenue  |6    |777.0 |\n",
      "|Revenue  |7    |800.0 |\n",
      "|Revenue  |8    |900.0 |\n",
      "+---------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "unPivotDF = df_pivot.unpivot(['Indicator'], ['1','2','3','4','5','6','7','8','9','10','11','12'],\\\n",
    "                             'Month', 'Amount')\n",
    "\n",
    "unPivotDF.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7595d51e-61b9-437a-b845-15fda9a04974",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Agregações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f283b-2885-4036-b112-efd8b938b288",
   "metadata": {},
   "source": [
    "count()\tUse groupBy() count() to return the number of rows for each group.\n",
    "mean()\tReturns the mean of values for each group.\n",
    "max()\tReturns the maximum of values for each group.\n",
    "min()\tReturns the minimum of values for each group.\n",
    "sum()\tReturns the total for values for each group.\n",
    "avg()\tReturns the average for values for each group.\n",
    "agg()\tUsing groupBy() agg() function, we can calculate more than one aggregate at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "38477d65-cbd9-4c8d-a7c6-0bfb05008f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unPivotDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "69f3b04a-52a9-4f97-83f6-aeeabb34f4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|avg(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|      612.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').mean('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "db9cf962-028d-4883-bfff-ef8b6b315a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|sum(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|     1200.0|\n",
      "|  Revenue|     6732.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').sum('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "f12a84c0-7da3-4f82-8d71-b31fa4b23465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|max(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|     1000.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').max('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ac4dfddf-5445-4d66-85a1-b5a0e6e9bcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|Indicator|min(Amount)|\n",
      "+---------+-----------+\n",
      "|   Profit|      100.0|\n",
      "|  Revenue|      300.0|\n",
      "+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "unPivotDF.groupBy('Indicator').min('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "52916042-9627-4362-9a8a-7cf7446a11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = unPivotDF.groupBy('Indicator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "7a2c6222-e09c-4c7b-9da5-399cb19764ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types as T, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "58b68a95-1592-4099-8f67-77b435b8320b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------------------------------------------------------------------+\n",
      "|Indicator|collect_list(Amount)                                                                |\n",
      "+---------+------------------------------------------------------------------------------------+\n",
      "|Profit   |[100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]|\n",
      "|Revenue  |[500.0, 500.0, 500.0, 500.0, 555.0, 777.0, 800.0, 900.0, 1000.0, 300.0, 400.0]      |\n",
      "+---------+------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped.agg(F.collect_list(F.col('Amount'))\n",
    "              ).show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6c226074-2027-4444-9aca-5bd638cc85a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+----------+\n",
      "|job_id|           jod_title|min_salary|max_salary|\n",
      "+------+--------------------+----------+----------+\n",
      "|     1|   Public Accountant|    4200.0|    9000.0|\n",
      "|     2|  Accounting Manager|    8200.0|   16000.0|\n",
      "|     3|Administration As...|    3000.0|    6000.0|\n",
      "|     4|           President|   20000.0|   40000.0|\n",
      "|     5|Administration Vi...|   15000.0|   30000.0|\n",
      "|     6|          Accountant|    4200.0|    9000.0|\n",
      "|     7|     Finance Manager|    8200.0|   16000.0|\n",
      "|     8|Human Resources R...|    4000.0|    9000.0|\n",
      "|     9|          Programmer|    4000.0|   10000.0|\n",
      "|    10|   Marketing Manager|    9000.0|   15000.0|\n",
      "|    11|Marketing Represe...|    4000.0|    9000.0|\n",
      "|    12|Public Relations ...|    4500.0|   10500.0|\n",
      "|    13|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|    14|  Purchasing Manager|    8000.0|   15000.0|\n",
      "|    15|       Sales Manager|   10000.0|   20000.0|\n",
      "|    16|Sales Representative|    6000.0|   12000.0|\n",
      "|    17|      Shipping Clerk|    2500.0|    5500.0|\n",
      "|    18|         Stock Clerk|    2000.0|    5000.0|\n",
      "|    19|       Stock Manager|    5500.0|    8500.0|\n",
      "+------+--------------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_jobs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "32aad32d-9dab-465b-9d62-2a0e9df6fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicao = df_employees.job_id == df_jobs.job_id\n",
    "df_jobs_joined = df_jobs.join(df_employees, condicao , 'inner').select(df_employees['*'],\\\n",
    "                                                                       df_jobs['jod_title'],\\\n",
    "                                                                       df_jobs['min_salary'],\\\n",
    "                                                                       df_jobs['max_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fc0f1f7a-c588-4779-8938-d21c7be9e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "|employee_id| first_name| last_name|               email|phone_number| hire_date|job_id| salary|manager_id|department_id|           jod_title|min_salary|max_salary|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "|        100|     Steven|      King|steven.king@sqltu...|515.123.4567|1987-06-17|     4|24000.0|      NULL|            9|           President|   20000.0|   40000.0|\n",
      "|        101|      Neena|   Kochhar|neena.kochhar@sql...|515.123.4568|1989-09-21|     5|17000.0|       100|            9|Administration Vi...|   15000.0|   30000.0|\n",
      "|        102|        Lex|   De Haan|lex.de haan@sqltu...|515.123.4569|1993-01-13|     5|17000.0|       100|            9|Administration Vi...|   15000.0|   30000.0|\n",
      "|        103|  Alexander|    Hunold|alexander.hunold@...|590.423.4567|1990-01-03|     9| 9000.0|       102|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        104|      Bruce|     Ernst|bruce.ernst@sqltu...|590.423.4568|1991-05-21|     9| 6000.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        105|      David|    Austin|david.austin@sqlt...|590.423.4569|1997-06-25|     9| 4800.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        106|      Valli| Pataballa|valli.pataballa@s...|590.423.4560|1998-02-05|     9| 4800.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        107|      Diana|   Lorentz|diana.lorentz@sql...|590.423.5567|1999-02-07|     9| 4200.0|       103|            6|          Programmer|    4000.0|   10000.0|\n",
      "|        108|      Nancy| Greenberg|nancy.greenberg@s...|515.124.4569|1994-08-17|     7|12000.0|       101|           10|     Finance Manager|    8200.0|   16000.0|\n",
      "|        109|     Daniel|    Faviet|daniel.faviet@sql...|515.124.4169|1994-08-16|     6| 9000.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        110|       John|      Chen|john.chen@sqltuto...|515.124.4269|1997-09-28|     6| 8200.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        111|     Ismael|   Sciarra|ismael.sciarra@sq...|515.124.4369|1997-09-30|     6| 7700.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        112|Jose Manuel|     Urman|jose manuel.urman...|515.124.4469|1998-03-07|     6| 7800.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        113|       Luis|      Popp|luis.popp@sqltuto...|515.124.4567|1999-12-07|     6| 6900.0|       108|           10|          Accountant|    4200.0|    9000.0|\n",
      "|        114|        Den|  Raphaely|den.raphaely@sqlt...|515.127.4561|1994-12-07|    14|11000.0|       100|            3|  Purchasing Manager|    8000.0|   15000.0|\n",
      "|        115|  Alexander|      Khoo|alexander.khoo@sq...|515.127.4562|1995-05-18|    13| 3100.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        116|     Shelli|     Baida|shelli.baida@sqlt...|515.127.4563|1997-12-24|    13| 2900.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        117|      Sigal|    Tobias|sigal.tobias@sqlt...|515.127.4564|1997-07-24|    13| 2800.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        118|        Guy|    Himuro|guy.himuro@sqltut...|515.127.4565|1998-11-15|    13| 2600.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "|        119|      Karen|Colmenares|karen.colmenares@...|515.127.4566|1999-08-10|    13| 2500.0|       114|            3|    Purchasing Clerk|    2500.0|    5500.0|\n",
      "+-----------+-----------+----------+--------------------+------------+----------+------+-------+----------+-------------+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_jobs_joined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6e3c945a-b0d0-40df-8801-7e0021b32f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+\n",
      "|Indicator|   sum| mean|\n",
      "+---------+------+-----+\n",
      "|   Profit|1200.0|100.0|\n",
      "|  Revenue|6732.0|612.0|\n",
      "+---------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,count,mean\n",
    "\n",
    "unPivotDF.groupBy('Indicator').agg(\n",
    "    sum('Amount').alias('sum'),\n",
    "    mean('Amount').alias('mean')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbaa89-621b-4684-bbb0-15b88b5adfbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3eddb7-81d4-44c7-8295-2f0233267d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890538c3-29af-485a-9b45-9e8cf7a0ae79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c6b8c-8f8d-40d7-8376-c994afc31f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3be6252-1970-4568-aead-14e88b7e89ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337aafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_orders = '../../datalake/bronze/csv/olist/orders'\n",
    "df_orders.write.format('parquet').mode('overwrite').save(path_orders )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cbdb36",
   "metadata": {},
   "source": [
    "### Selecionando e manipulando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders.select('order_id','customer_id','order_status','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date',\\\n",
    "                'order_delivered_customer_date','order_estimated_delivery_date').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d4177a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: string (nullable = true)\n",
      " |-- order_approved_at: string (nullable = true)\n",
      " |-- order_delivered_carrier_date: string (nullable = true)\n",
      " |-- order_delivered_customer_date: string (nullable = true)\n",
      " |-- order_estimated_delivery_date: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7e326c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|order_id                        |customer_id                     |order_status|order_purchase_timestamp|order_approved_at  |order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|\n",
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|e481f51cbdc54678b7cc49136f2d6af7|9ef432eb6251297304e76186b10a928d|delivered   |2017-10-02 10:56:33     |2017-10-02 11:07:15|2017-10-04 19:55:00         |2017-10-10 21:25:13          |2017-10-18 00:00:00          |\n",
      "|53cdb2fc8bc7dce0b6741e2150273451|b0830fb4747a6c6d20dea0b8c802d7ef|delivered   |2018-07-24 20:41:37     |2018-07-26 03:24:27|2018-07-26 14:31:00         |2018-08-07 15:27:45          |2018-08-13 00:00:00          |\n",
      "|47770eb9100c2d0c44946d9cf07ec65d|41ce2a54c0b03bf3443c3d931a367089|delivered   |2018-08-08 08:38:49     |2018-08-08 08:55:23|2018-08-08 13:50:00         |2018-08-17 18:06:29          |2018-09-04 00:00:00          |\n",
      "|949d5b44dbf5de918fe9c16f97b45f8a|f88197465ea7920adcdbec7375364d82|delivered   |2017-11-18 19:28:06     |2017-11-18 19:45:59|2017-11-22 13:39:59         |2017-12-02 00:28:42          |2017-12-15 00:00:00          |\n",
      "|ad21c59c0840e6cb83a9ceb5573f8159|8ab97904e6daea8866dbdbc4fb7aad2c|delivered   |2018-02-13 21:18:39     |2018-02-13 22:20:29|2018-02-14 19:46:34         |2018-02-16 18:17:02          |2018-02-26 00:00:00          |\n",
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders.select('order_id','customer_id','order_status','order_purchase_timestamp','order_approved_at','order_delivered_carrier_date',\\\n",
    "                'order_delivered_customer_date','order_estimated_delivery_date').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08701baf",
   "metadata": {},
   "source": [
    "### Colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1eff0",
   "metadata": {},
   "source": [
    "As colunas são unidades de manipulação de dados do Spark. \n",
    "Podemos referencias colunas de algumas formas <br>\n",
    "* col('nome_coluna') <br>\n",
    "* dataframe['nome_coluna'] <br>\n",
    "* dataframe.nome_coluna <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae8b2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+---------------+----------------+----------------+\n",
      "|            order_id|         customer_id|order_status|aproved_year_at|aproved_month_at|aproved_month_at|\n",
      "+--------------------+--------------------+------------+---------------+----------------+----------------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|           2017|              10|     02 11:07:15|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|           2018|              07|     26 03:24:27|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|           2018|              08|     08 08:55:23|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|           2017|              11|     18 19:45:59|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|           2018|              02|     13 22:20:29|\n",
      "+--------------------+--------------------+------------+---------------+----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "(\n",
    "df_orders.select('order_id', 'customer_id', 'order_status', \n",
    "F.split(F.col('order_approved_at'), '-').getItem(0).alias('aproved_year_at'),\n",
    "F.split(df_orders['order_approved_at'], '-').getItem(1).alias('aproved_month_at'),\n",
    "F.split(df_orders.order_approved_at, '-').getItem(2).alias('aproved_month_at')).show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a1246",
   "metadata": {},
   "source": [
    "### Expressões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "81227d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|\n",
      "+--------------------+--------------------+------------+-------------------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|          DELIVERED|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|          DELIVERED|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|          DELIVERED|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|          DELIVERED|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|          DELIVERED|\n",
      "+--------------------+--------------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "(\n",
    "    df_orders.select('order_id', 'customer_id', 'order_status', \n",
    "    F.expr('upper(order_status)'), )                    \n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e1f31fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|          DELIVERED|2017|   10| 02|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|          DELIVERED|2018|   07| 26|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|          DELIVERED|2018|   08| 08|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|          DELIVERED|2017|   11| 18|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|          DELIVERED|2018|   02| 13|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "(\n",
    "    df_orders.select('order_id', 'customer_id', 'order_status', \n",
    "    expr('upper(order_status)'),\n",
    "    expr('substring(order_approved_at, 0,4) as year'),\n",
    "    expr('substring(order_approved_at, 6,2) as month'),\n",
    "    expr('substring(order_approved_at, 9,2) as day'))                    \n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "aa2f2dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------------------+\n",
      "|            order_id|order_status|order_estimated_delivery_date|\n",
      "+--------------------+------------+-----------------------------+\n",
      "|e481f51cbdc54678b...|   delivered|          2017-10-18 00:00:00|\n",
      "|53cdb2fc8bc7dce0b...|   delivered|          2018-08-13 00:00:00|\n",
      "|47770eb9100c2d0c4...|   delivered|          2018-09-04 00:00:00|\n",
      "|949d5b44dbf5de918...|   delivered|          2017-12-15 00:00:00|\n",
      "|ad21c59c0840e6cb8...|   delivered|          2018-02-26 00:00:00|\n",
      "|a4591c265e18cb1dc...|   delivered|          2017-08-01 00:00:00|\n",
      "|136cce7faa42fdb2c...|    invoiced|          2017-05-09 00:00:00|\n",
      "|6514b8ad8028c9f2c...|   delivered|          2017-06-07 00:00:00|\n",
      "|76c6e866289321a7c...|   delivered|          2017-03-06 00:00:00|\n",
      "|e69bfb5eb88e0ed6a...|   delivered|          2017-08-23 00:00:00|\n",
      "+--------------------+------------+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cols = ['order_id', 'order_status', 'order_estimated_delivery_date']\n",
    "df_orders.select(cols).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fdf0a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-----------------------------+\n",
      "|         customer_id|            order_id|order_status|order_estimated_delivery_date|\n",
      "+--------------------+--------------------+------------+-----------------------------+\n",
      "|9ef432eb625129730...|e481f51cbdc54678b...|   delivered|          2017-10-18 00:00:00|\n",
      "|b0830fb4747a6c6d2...|53cdb2fc8bc7dce0b...|   delivered|          2018-08-13 00:00:00|\n",
      "|41ce2a54c0b03bf34...|47770eb9100c2d0c4...|   delivered|          2018-09-04 00:00:00|\n",
      "|f88197465ea7920ad...|949d5b44dbf5de918...|   delivered|          2017-12-15 00:00:00|\n",
      "|8ab97904e6daea886...|ad21c59c0840e6cb8...|   delivered|          2018-02-26 00:00:00|\n",
      "|503740e9ca751ccdd...|a4591c265e18cb1dc...|   delivered|          2017-08-01 00:00:00|\n",
      "|ed0271e0b7da060a3...|136cce7faa42fdb2c...|    invoiced|          2017-05-09 00:00:00|\n",
      "|9bdf08b4b3b52b552...|6514b8ad8028c9f2c...|   delivered|          2017-06-07 00:00:00|\n",
      "|f54a9f0e6b351c431...|76c6e866289321a7c...|   delivered|          2017-03-06 00:00:00|\n",
      "|31ad1d1b63eb99624...|e69bfb5eb88e0ed6a...|   delivered|          2017-08-23 00:00:00|\n",
      "+--------------------+--------------------+------------+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols = ['order_id', 'order_status', 'order_estimated_delivery_date']\n",
    "df_orders.select('customer_id', *cols).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc44145",
   "metadata": {},
   "source": [
    "Observações:\n",
    "* Podemos realizar operações sobre colunas selecionadas. \n",
    "* O DataFrame resultante resultante das operações vai obedeçer a order das colunas em que ele foi criado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "64e08625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|order_id                        |customer_id                     |order_status|order_purchase_timestamp|order_approved_at  |order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|\n",
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "|e481f51cbdc54678b7cc49136f2d6af7|9ef432eb6251297304e76186b10a928d|delivered   |2017-10-02 10:56:33     |2017-10-02 11:07:15|2017-10-04 19:55:00         |2017-10-10 21:25:13          |2017-10-18 00:00:00          |\n",
      "|53cdb2fc8bc7dce0b6741e2150273451|b0830fb4747a6c6d20dea0b8c802d7ef|delivered   |2018-07-24 20:41:37     |2018-07-26 03:24:27|2018-07-26 14:31:00         |2018-08-07 15:27:45          |2018-08-13 00:00:00          |\n",
      "+--------------------------------+--------------------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1dd8082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orders_selected =  (\n",
    "    df_orders.select('order_id', 'customer_id', 'order_status', \n",
    "    expr('upper(order_status)'),\n",
    "    expr('substring(order_approved_at, 0,4) as year'),\n",
    "    expr('substring(order_approved_at, 6,2) as month'),\n",
    "    expr('substring(order_approved_at, 9,2) as day'))   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4fd5bbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+\n",
      "|            order_id|         customer_id|order_status|      date|\n",
      "+--------------------+--------------------+------------+----------+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   DELIVERED|2017-10-02|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   DELIVERED|2018-07-26|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   DELIVERED|2018-08-08|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   DELIVERED|2017-11-18|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   DELIVERED|2018-02-13|\n",
      "|a4591c265e18cb1dc...|503740e9ca751ccdd...|   DELIVERED|2017-07-09|\n",
      "|136cce7faa42fdb2c...|ed0271e0b7da060a3...|    INVOICED|2017-04-13|\n",
      "|6514b8ad8028c9f2c...|9bdf08b4b3b52b552...|   DELIVERED|2017-05-16|\n",
      "|76c6e866289321a7c...|f54a9f0e6b351c431...|   DELIVERED|2017-01-25|\n",
      "|e69bfb5eb88e0ed6a...|31ad1d1b63eb99624...|   DELIVERED|2017-07-29|\n",
      "+--------------------+--------------------+------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.selectExpr('order_id', 'customer_id','upper(order_status) as order_status','concat(year,\"-\",month,\"-\",day) as date').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d7ec1",
   "metadata": {},
   "source": [
    "###  Selecionando valores únicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8b604a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2016|\n",
      "|2017|\n",
      "|null|\n",
      "|2018|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.select('year').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d58df45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month| day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "|00b1cb0320190ca0d...|3532ba38a3fd24225...|    canceled|           CANCELED|null| null|null|\n",
      "|d3c8851a6651eeff2...|957f8e082185574de...|  processing|         PROCESSING|2016|   10|  06|\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|          DELIVERED|2017|   10|  02|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|          DELIVERED|2018|   07|  26|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.dropDuplicates(subset=['year']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300e171",
   "metadata": {},
   "source": [
    "### Filtrando registros e condições"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dd008f",
   "metadata": {},
   "source": [
    "Operadores lógicos disponíveis:\n",
    "* e: &\n",
    "* ou: |\n",
    "* não: ~\n",
    "\n",
    "As funções `filter()` e `where()` podem ser utilizadas no processo de filtragem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2f1f64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|e481f51cbdc54678b...|9ef432eb625129730...|   delivered|          DELIVERED|2017|   10| 02|\n",
      "|53cdb2fc8bc7dce0b...|b0830fb4747a6c6d2...|   delivered|          DELIVERED|2018|   07| 26|\n",
      "|47770eb9100c2d0c4...|41ce2a54c0b03bf34...|   delivered|          DELIVERED|2018|   08| 08|\n",
      "|949d5b44dbf5de918...|f88197465ea7920ad...|   delivered|          DELIVERED|2017|   11| 18|\n",
      "|ad21c59c0840e6cb8...|8ab97904e6daea886...|   delivered|          DELIVERED|2018|   02| 13|\n",
      "|a4591c265e18cb1dc...|503740e9ca751ccdd...|   delivered|          DELIVERED|2017|   07| 09|\n",
      "|136cce7faa42fdb2c...|ed0271e0b7da060a3...|    invoiced|           INVOICED|2017|   04| 13|\n",
      "|6514b8ad8028c9f2c...|9bdf08b4b3b52b552...|   delivered|          DELIVERED|2017|   05| 16|\n",
      "|76c6e866289321a7c...|f54a9f0e6b351c431...|   delivered|          DELIVERED|2017|   01| 25|\n",
      "|e69bfb5eb88e0ed6a...|31ad1d1b63eb99624...|   delivered|          DELIVERED|2017|   07| 29|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.filter(~(col('year') == 'null')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50cb419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month| day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "|00b1cb0320190ca0d...|3532ba38a3fd24225...|    canceled|           CANCELED|null| null|null|\n",
      "|ed3efbd3a87bea76c...|191984a8ba4cbb214...|    canceled|           CANCELED|null| null|null|\n",
      "|df8282afe61008dc2...|aa797b187b5466bc6...|    canceled|           CANCELED|null| null|null|\n",
      "|8d4c637f1accf7a88...|b1dd715db389a2077...|    canceled|           CANCELED|null| null|null|\n",
      "|7a9d4c7f9b0683378...|7f71ae48074c0cfec...|    canceled|           CANCELED|null| null|null|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.filter((col('year').isNull())).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9562b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|order_status|\n",
      "+------------+\n",
      "|     shipped|\n",
      "|    canceled|\n",
      "|    invoiced|\n",
      "|     created|\n",
      "|   delivered|\n",
      "| unavailable|\n",
      "|  processing|\n",
      "|    approved|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders_selected.select('order_status').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8581d431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|c4e980a1d822db426...|88dc22aad9cf20898...|    invoiced|           INVOICED|2016|   10| 09|\n",
      "|35b8e54d765e6b217...|1aaa5eaa9dd9bafb3...|    invoiced|           INVOICED|2016|   10| 07|\n",
      "|711b9be9c346d9ecd...|81e4aed5ab4253757...|    invoiced|           INVOICED|2016|   10| 04|\n",
      "|a6475bb7a50387e3c...|442d66f0d96f65609...|    invoiced|           INVOICED|2016|   10| 05|\n",
      "|dd845e1cdb19f08d0...|01f7b7a4e25cda9ce...|    invoiced|           INVOICED|2016|   10| 10|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_orders_selected.filter((col('year') == '2016') & (col('order_status') == 'invoiced'))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a2c5fc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|8e24261a7e58791d1...|64a254d30eed42cd0...| unavailable|        UNAVAILABLE|2017|   11| 16|\n",
      "|37553832a3a89c9b2...|7607cd563696c27ed...| unavailable|        UNAVAILABLE|2017|   08| 17|\n",
      "|2f634e2cebf8c0283...|7353b0fb8e8d9675e...| unavailable|        UNAVAILABLE|2017|   09| 28|\n",
      "|ee0db22a8e742b752...|aae50600d30bf2efe...| unavailable|        UNAVAILABLE|2017|   08| 24|\n",
      "|6ad57aecbae806a7e...|d31dbd02ac052d662...| unavailable|        UNAVAILABLE|2017|   11| 30|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_orders_selected.filter(((col('order_status') == 'unavailable') | (col('order_status') == 'canceled')) & (col('year') == '2017')).show(5)\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bff02ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|8e24261a7e58791d1...|64a254d30eed42cd0...| unavailable|        UNAVAILABLE|2017|   11| 16|\n",
      "|37553832a3a89c9b2...|7607cd563696c27ed...| unavailable|        UNAVAILABLE|2017|   08| 17|\n",
      "|2f634e2cebf8c0283...|7353b0fb8e8d9675e...| unavailable|        UNAVAILABLE|2017|   09| 28|\n",
      "|ee0db22a8e742b752...|aae50600d30bf2efe...| unavailable|        UNAVAILABLE|2017|   08| 24|\n",
      "|6ad57aecbae806a7e...|d31dbd02ac052d662...| unavailable|        UNAVAILABLE|2017|   11| 30|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_orders_selected.filter((col('order_status').isin('unavailable', 'canceled')) & (col('year') == '2017')).show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5a7770c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|8e24261a7e58791d1...|64a254d30eed42cd0...| unavailable|        UNAVAILABLE|2017|   11| 16|\n",
      "|37553832a3a89c9b2...|7607cd563696c27ed...| unavailable|        UNAVAILABLE|2017|   08| 17|\n",
      "|2f634e2cebf8c0283...|7353b0fb8e8d9675e...| unavailable|        UNAVAILABLE|2017|   09| 28|\n",
      "|ee0db22a8e742b752...|aae50600d30bf2efe...| unavailable|        UNAVAILABLE|2017|   08| 24|\n",
      "|6ad57aecbae806a7e...|d31dbd02ac052d662...| unavailable|        UNAVAILABLE|2017|   11| 30|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_orders_selected\n",
    "    .filter((col('order_status').isin('unavailable', 'canceled')))\n",
    "    .filter((col('year') == '2017'))\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da86f7",
   "metadata": {},
   "source": [
    "### Utilizando expressões no filtro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bc0327eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|            order_id|         customer_id|order_status|upper(order_status)|year|month|day|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "|8e24261a7e58791d1...|64a254d30eed42cd0...| unavailable|        UNAVAILABLE|2017|   11| 16|\n",
      "|37553832a3a89c9b2...|7607cd563696c27ed...| unavailable|        UNAVAILABLE|2017|   08| 17|\n",
      "|2f634e2cebf8c0283...|7353b0fb8e8d9675e...| unavailable|        UNAVAILABLE|2017|   09| 28|\n",
      "|ee0db22a8e742b752...|aae50600d30bf2efe...| unavailable|        UNAVAILABLE|2017|   08| 24|\n",
      "|6ad57aecbae806a7e...|d31dbd02ac052d662...| unavailable|        UNAVAILABLE|2017|   11| 30|\n",
      "+--------------------+--------------------+------------+-------------------+----+-----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    df_orders_selected\n",
    "    .filter('order_status in (\"unavailable\", \"canceled\") and year == \"2017\"')\n",
    "    .show(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5627fc",
   "metadata": {},
   "source": [
    "#### Observações\n",
    "Quando nos referimos às colunas por meio da função `col()`, temos acesso à diversos métodos das colunas que podem ser utilizados para auxliar na filtragem do DataFrame. Alguns deles são:\n",
    "* `isin()`: checa se a coluna contém os valores listados na função.\n",
    "* `contains()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (não aceita regex). Aceita uma outra coluna de texto.\n",
    "* `like()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (não aceita regex). Funciona de forma similar ao \"LIKE\" do SQL.\n",
    "* `rlike()`: utilizado para verificar se uma coluna de texto contém algum padrão especificado (**aceita regex**). Funciona de forma similar ao \"RLIKE\" do SQL.\n",
    "* `startswith()`: utilizado para verificar se uma coluna de texto começa com algum padrão especificado (**aceita regex**).\n",
    "* `endswith()`: utilizado para verificar se uma coluna de texto termina com algum padrão especificado (**aceita regex**).\n",
    "* `between()`: checa se os valores da coluna estão dentro do intervalo especificado. Os dois lados do intervalo são inclusivos.\n",
    "* `isNull()`: retorna True se o valor da coluna é nulo\n",
    "* `isNotNull()`: retorna True se o valor da coluna não é nulo\n",
    "\n",
    "Outros métodos úteis:\n",
    "* `alias()/name()`: usado para renomear as colunas em operações como select() e agg()\n",
    "* `astype()/cast()`: usado para mudar o tipo das colunas. Aceita tanto um string como um tipo especificado pelo módulo pyspark.sql.types\n",
    "* `substr()`: utilizado para cortar um string com base em índices dos caracteres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effb27cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
